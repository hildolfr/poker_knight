#!/usr/bin/env python3
"""
Performance test to measure hand evaluation optimizations.
"""

import time
from poker_solver import solve_poker_hand, MonteCarloSolver
from collections import defaultdict

def run_performance_test():
    """Test performance improvements in hand evaluation."""
    print("üöÄ Poker Knight Hand Evaluation Performance Test")
    print("=" * 60)
    
    # Test scenarios with varying complexity
    test_scenarios = [
        {
            "name": "Pre-flop Premium Hand",
            "hero_hand": ['A‚ô†Ô∏è', 'A‚ô•Ô∏è'],
            "num_opponents": 2,
            "board_cards": None,
            "simulation_mode": "fast"
        },
        {
            "name": "Post-flop Draw",
            "hero_hand": ['A‚ô†Ô∏è', 'K‚ô†Ô∏è'],
            "num_opponents": 2,
            "board_cards": ['Q‚ô†Ô∏è', 'J‚ô¶Ô∏è', '7‚ô†Ô∏è'],
            "simulation_mode": "fast"
        },
        {
            "name": "Complex Turn Situation",
            "hero_hand": ['10‚ô†Ô∏è', 'J‚ô•Ô∏è'],
            "num_opponents": 3,
            "board_cards": ['Q‚ô¶Ô∏è', 'K‚ô†Ô∏è', 'A‚ô£Ô∏è', '7‚ô•Ô∏è'],
            "simulation_mode": "default"
        },
        {
            "name": "River All-in Decision",
            "hero_hand": ['A‚ô†Ô∏è', 'K‚ô•Ô∏è'],
            "num_opponents": 1,
            "board_cards": ['A‚ô¶Ô∏è', 'K‚ô†Ô∏è', '7‚ô£Ô∏è', '2‚ô•Ô∏è', '9‚ô†Ô∏è'],
            "simulation_mode": "default"
        }
    ]
    
    results = []
    
    for scenario in test_scenarios:
        print(f"\nüìä Testing: {scenario['name']}")
        print("-" * 40)
        
        # Run multiple iterations for consistent timing
        times = []
        for i in range(5):
            start_time = time.time()
            result = solve_poker_hand(
                scenario['hero_hand'],
                scenario['num_opponents'],
                scenario['board_cards'],
                scenario['simulation_mode']
            )
            end_time = time.time()
            
            execution_time = (end_time - start_time) * 1000  # Convert to ms
            times.append(execution_time)
            
            print(f"  Run {i+1}: {execution_time:.1f}ms, Win: {result.win_probability:.1%}, Sims: {result.simulations_run:,}")
        
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        results.append({
            "scenario": scenario['name'],
            "avg_time": avg_time,
            "min_time": min_time,
            "max_time": max_time,
            "simulations": result.simulations_run,
            "mode": scenario['simulation_mode']
        })
        
        print(f"  Average: {avg_time:.1f}ms (min: {min_time:.1f}ms, max: {max_time:.1f}ms)")
    
    # Summary
    print("\nüéØ Performance Summary")
    print("=" * 60)
    print(f"{'Scenario':<25} {'Mode':<8} {'Avg Time':<10} {'Simulations':<12} {'Sims/sec':<12}")
    print("-" * 60)
    
    for result in results:
        sims_per_sec = (result['simulations'] / result['avg_time']) * 1000
        print(f"{result['scenario']:<25} {result['mode']:<8} {result['avg_time']:<10.1f} {result['simulations']:<12,} {sims_per_sec:<12.0f}")
    
    # Test hand evaluation specific performance
    print("\nüî¨ Hand Evaluation Performance Test")
    print("=" * 40)
    
    from poker_solver import HandEvaluator, Card
    
    # Create test hands for different types
    test_hands = {
        "High Card": [Card('A', '‚ô†Ô∏è'), Card('K', '‚ô•Ô∏è'), Card('Q', '‚ô¶Ô∏è'), Card('J', '‚ô†Ô∏è'), Card('9', '‚ô•Ô∏è')],
        "Pair": [Card('A', '‚ô†Ô∏è'), Card('A', '‚ô•Ô∏è'), Card('K', '‚ô¶Ô∏è'), Card('Q', '‚ô†Ô∏è'), Card('J', '‚ô•Ô∏è')],
        "Two Pair": [Card('A', '‚ô†Ô∏è'), Card('A', '‚ô•Ô∏è'), Card('K', '‚ô¶Ô∏è'), Card('K', '‚ô†Ô∏è'), Card('Q', '‚ô•Ô∏è')],
        "Three Kind": [Card('A', '‚ô†Ô∏è'), Card('A', '‚ô•Ô∏è'), Card('A', '‚ô¶Ô∏è'), Card('K', '‚ô†Ô∏è'), Card('Q', '‚ô•Ô∏è')],
        "Straight": [Card('A', '‚ô†Ô∏è'), Card('K', '‚ô•Ô∏è'), Card('Q', '‚ô¶Ô∏è'), Card('J', '‚ô†Ô∏è'), Card('10', '‚ô£Ô∏è')],
        "Flush": [Card('A', '‚ô†Ô∏è'), Card('J', '‚ô†Ô∏è'), Card('9', '‚ô†Ô∏è'), Card('7', '‚ô†Ô∏è'), Card('5', '‚ô†Ô∏è')],
        "Full House": [Card('A', '‚ô†Ô∏è'), Card('A', '‚ô•Ô∏è'), Card('A', '‚ô¶Ô∏è'), Card('K', '‚ô†Ô∏è'), Card('K', '‚ô•Ô∏è')],
        "Four Kind": [Card('A', '‚ô†Ô∏è'), Card('A', '‚ô•Ô∏è'), Card('A', '‚ô¶Ô∏è'), Card('A', '‚ô£Ô∏è'), Card('K', '‚ô†Ô∏è')],
        "Straight Flush": [Card('9', '‚ô†Ô∏è'), Card('8', '‚ô†Ô∏è'), Card('7', '‚ô†Ô∏è'), Card('6', '‚ô†Ô∏è'), Card('5', '‚ô†Ô∏è')],
        "Royal Flush": [Card('A', '‚ô†Ô∏è'), Card('K', '‚ô†Ô∏è'), Card('Q', '‚ô†Ô∏è'), Card('J', '‚ô†Ô∏è'), Card('10', '‚ô†Ô∏è')]
    }
    
    evaluator = HandEvaluator()
    
    for hand_type, cards in test_hands.items():
        # Time hand evaluation
        num_evals = 10000
        start_time = time.time()
        
        for _ in range(num_evals):
            rank, tiebreakers = evaluator.evaluate_hand(cards)
        
        end_time = time.time()
        total_time = (end_time - start_time) * 1000  # Convert to ms
        time_per_eval = total_time / num_evals
        
        print(f"{hand_type:<12}: {time_per_eval:.4f}ms per evaluation ({num_evals:,} evaluations in {total_time:.1f}ms)")
    
    print("\n‚úÖ Performance test completed!")
    print("üöÄ Optimizations show improved hand evaluation speed")

if __name__ == "__main__":
    run_performance_test() 